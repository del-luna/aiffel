{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f37ab76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "train_data = pd.read_table('./data/ratings_train.txt')\n",
    "test_data = pd.read_table('./data/ratings_test.txt')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65c93b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "def load_data(train_data, test_data, num_words=10000):\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    train_data = train_data.dropna(how = 'any') \n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data = test_data.dropna(how = 'any') \n",
    "\n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_train.append(temp_X)\n",
    "\n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_test.append(temp_X)\n",
    "\n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(10000-4)\n",
    "    vocab = ['<PAD>', '<BOS>', '<UNK>', '<UNUSED>'] + [key for key, _ in counter]\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "\n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in wordlist]\n",
    "\n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "\n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
    "    \n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d545276",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8784c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a2566fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이야기 구먼 . . 솔직히 재미 없 다 . . 평점 조정'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_decoded_sentence(X_train[3],index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c6a95d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  15.96940191154864\n",
      "문장길이 최대 :  116\n",
      "문장길이 표준편차 :  12.843571191092\n",
      "pad_sequences maxlen :  41\n",
      "전체 문장의 0.9342988343341575%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(X_train) + list(X_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77b7fede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146182, 41)\n"
     ]
    }
   ],
   "source": [
    "X_train = keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='post', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "X_test = keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='post', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1e091cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126182, 41)\n",
      "(126182,)\n",
      "(20000, 41)\n",
      "(20000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 20000건 분리\n",
    "x_val = X_train[:20000]   \n",
    "y_val = y_train[:20000]\n",
    "\n",
    "# validation set을 제외한 나머지\n",
    "partial_X_train = X_train[20000:]  \n",
    "partial_y_train = y_train[20000:]\n",
    "\n",
    "print(partial_X_train.shape)\n",
    "print(partial_y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57a4eec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(index_to_word)\n",
    "word_vector_dim = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb062451",
   "metadata": {},
   "source": [
    "## 1-D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7639f482",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 300)         3000000   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 256)         537856    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 64)          114752    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 520       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,653,137\n",
      "Trainable params: 3,653,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CNN_model = keras.Sequential(name=\"CNN\")\n",
    "CNN_model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "CNN_model.add(keras.layers.Conv1D(256, 7, activation='relu'))\n",
    "CNN_model.add(keras.layers.MaxPooling1D(5))\n",
    "CNN_model.add(keras.layers.Conv1D(64, 7, activation='relu'))\n",
    "CNN_model.add(keras.layers.GlobalMaxPooling1D())\n",
    "CNN_model.add(keras.layers.Dense(8, activation='relu'))\n",
    "CNN_model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "CNN_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d786595",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd9298e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 300)         3000000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 9888      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,009,969\n",
      "Trainable params: 3,009,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LSTM_model = keras.Sequential(name=\"LSTM\")\n",
    "LSTM_model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "LSTM_model.add(keras.layers.LSTM(8, dropout=0.7))\n",
    "LSTM_model.add(keras.layers.Dense(8, activation='relu'))\n",
    "LSTM_model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "LSTM_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946369ed",
   "metadata": {},
   "source": [
    "## GMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef48128a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"GMP\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 300)         3000000   \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 2408      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,002,417\n",
      "Trainable params: 3,002,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "GMP_model = keras.Sequential(name=\"GMP\")\n",
    "GMP_model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "GMP_model.add(keras.layers.GlobalMaxPooling1D())\n",
    "GMP_model.add(keras.layers.Dense(8, activation='relu'))\n",
    "GMP_model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "GMP_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5b05ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CNN', 'LSTM', 'GMP']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lst = [CNN_model.name, LSTM_model.name, GMP_model.name]\n",
    "model_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99d7517d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Start fitting CNN ...\n",
      "Epoch 1/20\n",
      "247/247 [==============================] - 9s 23ms/step - loss: 0.3948 - accuracy: 0.8155 - val_loss: 0.3266 - val_accuracy: 0.8590\n",
      "Epoch 2/20\n",
      "247/247 [==============================] - 5s 21ms/step - loss: 0.2739 - accuracy: 0.8867 - val_loss: 0.3177 - val_accuracy: 0.8644\n",
      "Epoch 3/20\n",
      "247/247 [==============================] - 5s 21ms/step - loss: 0.1790 - accuracy: 0.9315 - val_loss: 0.3754 - val_accuracy: 0.8547\n",
      "Epoch 4/20\n",
      "247/247 [==============================] - 5s 21ms/step - loss: 0.0960 - accuracy: 0.9659 - val_loss: 0.4618 - val_accuracy: 0.8528\n",
      "Epoch 5/20\n",
      "247/247 [==============================] - 5s 21ms/step - loss: 0.0538 - accuracy: 0.9818 - val_loss: 0.6006 - val_accuracy: 0.8512\n",
      "Epoch 6/20\n",
      "247/247 [==============================] - 5s 22ms/step - loss: 0.0396 - accuracy: 0.9860 - val_loss: 0.7007 - val_accuracy: 0.8450\n",
      "Epoch 7/20\n",
      "247/247 [==============================] - 5s 22ms/step - loss: 0.0324 - accuracy: 0.9885 - val_loss: 0.7761 - val_accuracy: 0.8468\n",
      "Epoch 8/20\n",
      "247/247 [==============================] - 5s 22ms/step - loss: 0.0339 - accuracy: 0.9877 - val_loss: 0.7731 - val_accuracy: 0.8461\n",
      "Epoch 9/20\n",
      "247/247 [==============================] - 6s 22ms/step - loss: 0.0235 - accuracy: 0.9916 - val_loss: 0.8917 - val_accuracy: 0.8426\n",
      "Epoch 10/20\n",
      "247/247 [==============================] - 6s 23ms/step - loss: 0.0215 - accuracy: 0.9920 - val_loss: 0.8966 - val_accuracy: 0.8447\n",
      "Epoch 11/20\n",
      "247/247 [==============================] - 6s 23ms/step - loss: 0.0185 - accuracy: 0.9930 - val_loss: 1.0046 - val_accuracy: 0.8440\n",
      "Epoch 12/20\n",
      "247/247 [==============================] - 6s 23ms/step - loss: 0.0181 - accuracy: 0.9932 - val_loss: 0.9917 - val_accuracy: 0.8381\n",
      "Epoch 13/20\n",
      "247/247 [==============================] - 6s 22ms/step - loss: 0.0187 - accuracy: 0.9930 - val_loss: 0.9973 - val_accuracy: 0.8423\n",
      "Epoch 14/20\n",
      "247/247 [==============================] - 5s 22ms/step - loss: 0.0172 - accuracy: 0.9935 - val_loss: 1.0290 - val_accuracy: 0.8424\n",
      "Epoch 15/20\n",
      "247/247 [==============================] - 5s 22ms/step - loss: 0.0137 - accuracy: 0.9944 - val_loss: 1.1160 - val_accuracy: 0.8433\n",
      "Epoch 16/20\n",
      "247/247 [==============================] - 5s 22ms/step - loss: 0.0106 - accuracy: 0.9956 - val_loss: 1.2433 - val_accuracy: 0.8421\n",
      "Epoch 17/20\n",
      "247/247 [==============================] - 5s 22ms/step - loss: 0.0141 - accuracy: 0.9945 - val_loss: 1.2136 - val_accuracy: 0.8450\n",
      "Epoch 18/20\n",
      "247/247 [==============================] - 5s 22ms/step - loss: 0.0173 - accuracy: 0.9933 - val_loss: 1.0371 - val_accuracy: 0.8444\n",
      "Epoch 19/20\n",
      "247/247 [==============================] - 5s 22ms/step - loss: 0.0116 - accuracy: 0.9955 - val_loss: 1.1380 - val_accuracy: 0.8408\n",
      "Epoch 20/20\n",
      "247/247 [==============================] - 5s 22ms/step - loss: 0.0097 - accuracy: 0.9960 - val_loss: 1.2522 - val_accuracy: 0.8408\n",
      "Start evaluating CNN ...\n",
      "1537/1537 - 3s - loss: 1.2901 - accuracy: 0.8382\n",
      "----------------------------------------\n",
      "Start fitting LSTM ...\n",
      "Epoch 1/20\n",
      "247/247 [==============================] - 4s 10ms/step - loss: 0.5830 - accuracy: 0.6534 - val_loss: 0.3975 - val_accuracy: 0.8236\n",
      "Epoch 2/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.3712 - accuracy: 0.8416 - val_loss: 0.3511 - val_accuracy: 0.8503\n",
      "Epoch 3/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.3269 - accuracy: 0.8622 - val_loss: 0.3401 - val_accuracy: 0.8533\n",
      "Epoch 4/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.3083 - accuracy: 0.8703 - val_loss: 0.3394 - val_accuracy: 0.8551\n",
      "Epoch 5/20\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 0.2918 - accuracy: 0.8782 - val_loss: 0.3377 - val_accuracy: 0.8557\n",
      "Epoch 6/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.2795 - accuracy: 0.8831 - val_loss: 0.3392 - val_accuracy: 0.8571\n",
      "Epoch 7/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.2651 - accuracy: 0.8892 - val_loss: 0.3449 - val_accuracy: 0.8592\n",
      "Epoch 8/20\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 0.2531 - accuracy: 0.8951 - val_loss: 0.3402 - val_accuracy: 0.8588\n",
      "Epoch 9/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.2434 - accuracy: 0.8987 - val_loss: 0.3472 - val_accuracy: 0.8575\n",
      "Epoch 10/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.2344 - accuracy: 0.9029 - val_loss: 0.3655 - val_accuracy: 0.8574\n",
      "Epoch 11/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.2276 - accuracy: 0.9064 - val_loss: 0.3590 - val_accuracy: 0.8565\n",
      "Epoch 12/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.2196 - accuracy: 0.9103 - val_loss: 0.3773 - val_accuracy: 0.8569\n",
      "Epoch 13/20\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 0.2123 - accuracy: 0.9135 - val_loss: 0.3809 - val_accuracy: 0.8584\n",
      "Epoch 14/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.2065 - accuracy: 0.9159 - val_loss: 0.3785 - val_accuracy: 0.8584\n",
      "Epoch 15/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.2017 - accuracy: 0.9183 - val_loss: 0.3877 - val_accuracy: 0.8579\n",
      "Epoch 16/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.1967 - accuracy: 0.9203 - val_loss: 0.4033 - val_accuracy: 0.8556\n",
      "Epoch 17/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.1900 - accuracy: 0.9238 - val_loss: 0.4119 - val_accuracy: 0.8547\n",
      "Epoch 18/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.1865 - accuracy: 0.9249 - val_loss: 0.4229 - val_accuracy: 0.8547\n",
      "Epoch 19/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.1828 - accuracy: 0.9270 - val_loss: 0.4167 - val_accuracy: 0.8539\n",
      "Epoch 20/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.1777 - accuracy: 0.9297 - val_loss: 0.4223 - val_accuracy: 0.8550\n",
      "Start evaluating LSTM ...\n",
      "1537/1537 - 3s - loss: 0.4256 - accuracy: 0.8502\n",
      "----------------------------------------\n",
      "Start fitting GMP ...\n",
      "Epoch 1/20\n",
      "247/247 [==============================] - 2s 6ms/step - loss: 0.4990 - accuracy: 0.7606 - val_loss: 0.3481 - val_accuracy: 0.8469\n",
      "Epoch 2/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.3118 - accuracy: 0.8698 - val_loss: 0.3334 - val_accuracy: 0.8561\n",
      "Epoch 3/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.2606 - accuracy: 0.8952 - val_loss: 0.3375 - val_accuracy: 0.8569\n",
      "Epoch 4/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.2138 - accuracy: 0.9183 - val_loss: 0.3563 - val_accuracy: 0.8548\n",
      "Epoch 5/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.1663 - accuracy: 0.9413 - val_loss: 0.3849 - val_accuracy: 0.8537\n",
      "Epoch 6/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.1195 - accuracy: 0.9625 - val_loss: 0.4194 - val_accuracy: 0.8526\n",
      "Epoch 7/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.0809 - accuracy: 0.9782 - val_loss: 0.4644 - val_accuracy: 0.8483\n",
      "Epoch 8/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.0545 - accuracy: 0.9865 - val_loss: 0.5037 - val_accuracy: 0.8468\n",
      "Epoch 9/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.0378 - accuracy: 0.9913 - val_loss: 0.5430 - val_accuracy: 0.8448\n",
      "Epoch 10/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.0278 - accuracy: 0.9933 - val_loss: 0.5777 - val_accuracy: 0.8443\n",
      "Epoch 11/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.0218 - accuracy: 0.9946 - val_loss: 0.6096 - val_accuracy: 0.8456\n",
      "Epoch 12/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.0175 - accuracy: 0.9953 - val_loss: 0.6347 - val_accuracy: 0.8451\n",
      "Epoch 13/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 0.6639 - val_accuracy: 0.8443\n",
      "Epoch 14/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: 0.6899 - val_accuracy: 0.8438\n",
      "Epoch 15/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 0.7123 - val_accuracy: 0.8432\n",
      "Epoch 16/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.0104 - accuracy: 0.9964 - val_loss: 0.7431 - val_accuracy: 0.8435\n",
      "Epoch 17/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.0094 - accuracy: 0.9964 - val_loss: 0.7581 - val_accuracy: 0.8406\n",
      "Epoch 18/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.0084 - accuracy: 0.9967 - val_loss: 0.7715 - val_accuracy: 0.8442\n",
      "Epoch 19/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.0081 - accuracy: 0.9967 - val_loss: 0.7934 - val_accuracy: 0.8415\n",
      "Epoch 20/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.0076 - accuracy: 0.9968 - val_loss: 0.8138 - val_accuracy: 0.8431\n",
      "Start evaluating GMP ...\n",
      "1537/1537 - 2s - loss: 0.8210 - accuracy: 0.8417\n"
     ]
    }
   ],
   "source": [
    "model_result = {}\n",
    "\n",
    "for model_name in model_lst:\n",
    "    \n",
    "    if model_name == \"CNN\":\n",
    "        model = CNN_model\n",
    "    elif model_name == \"LSTM\":\n",
    "        model = LSTM_model\n",
    "    else :\n",
    "        model = GMP_model\n",
    "    \n",
    "    print('-'*40)\n",
    "    print(\"Start fitting {} ...\".format(model_name))\n",
    "    model.compile(optimizer='Adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    epochs=20\n",
    "\n",
    "    history = model.fit(partial_X_train,\n",
    "                        partial_y_train,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=512,\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        verbose=1)\n",
    "    \n",
    "    \n",
    "    print(\"Start evaluating {} ...\".format(model_name))\n",
    "    results = model.evaluate(X_test,  y_test, verbose=2)\n",
    "    model_result[model_name] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2062e1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CNN': [1.2901331186294556, 0.8381919264793396],\n",
       " 'LSTM': [0.4255813658237457, 0.8501739501953125],\n",
       " 'GMP': [0.8209972977638245, 0.8417112231254578]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f8aa96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_file_path = './data/ko.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28107544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "word2vec = Word2Vec.load(word2vec_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "854512f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1174/503750501.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  v1 = word2vec['사랑']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.3740246 , -1.7353463 ,  3.3915305 , -2.569253  , -1.4016607 ,\n",
       "        1.4556127 ,  0.9414557 ,  1.9207907 ,  0.16471806,  0.4838317 ,\n",
       "       -0.8547181 ,  2.0879807 ,  0.86741775,  0.87539405, -0.09962013,\n",
       "        0.22928311, -1.1858722 ,  0.00858838,  1.4999928 , -0.16196461,\n",
       "       -0.35184434, -0.92390764,  1.0849575 ,  0.3025011 ,  2.7021565 ,\n",
       "       -1.0263684 ,  0.32864776, -0.76589465, -2.510981  , -0.66225356,\n",
       "        2.8434615 ,  0.50130975, -1.021874  , -1.4366034 ,  1.1110784 ,\n",
       "        0.5812605 , -0.5830406 , -0.5785423 ,  1.3634988 ,  2.3074338 ,\n",
       "       -1.4314893 ,  0.45745876,  1.1073523 , -3.2135262 , -0.2898375 ,\n",
       "       -1.1622221 ,  1.2369208 , -0.7622987 , -0.37757635,  1.1376442 ,\n",
       "        0.01065568, -0.69105595,  1.5159112 ,  1.1534518 , -1.0119992 ,\n",
       "       -0.5757404 ,  1.1349088 , -1.1289831 ,  0.13004152,  2.0451715 ,\n",
       "       -0.23940353,  1.3604902 ,  0.72700524,  0.32545742,  1.0612459 ,\n",
       "        0.42252553,  1.1442151 ,  2.8774905 ,  2.4377263 , -1.340305  ,\n",
       "        0.12629706, -0.07772489, -0.59053177, -0.19007324,  0.1396541 ,\n",
       "       -1.8655105 ,  0.9401054 ,  0.5150856 ,  0.7795373 , -0.86505556,\n",
       "        0.11842118, -1.8303713 ,  1.337177  , -1.0102932 , -0.37180334,\n",
       "        0.00893255, -0.49141577, -1.05802   , -2.5987291 ,  0.9731856 ,\n",
       "        0.34080654, -2.5973568 ,  1.0046519 , -1.3914212 , -0.6504351 ,\n",
       "       -0.9010805 , -1.1341541 ,  0.75565654,  1.2941337 ,  0.0880572 ,\n",
       "       -1.0341461 , -0.1750075 , -0.01880708, -1.0835075 , -2.0333962 ,\n",
       "        1.1372623 ,  1.0626172 , -1.8369784 , -2.2662086 , -3.382057  ,\n",
       "        1.6751666 , -0.2988223 , -0.25563756, -1.5594274 ,  0.6313433 ,\n",
       "       -1.2667153 , -1.6857744 , -1.0949599 ,  0.7742313 , -0.6095523 ,\n",
       "        3.19503   ,  0.13200459,  1.7937473 , -2.8782516 ,  1.3821276 ,\n",
       "        2.2895143 ,  0.0741943 , -0.41046414,  1.438796  ,  0.19373988,\n",
       "        1.4294034 ,  1.5025262 ,  1.4849502 ,  1.5754777 ,  2.7793512 ,\n",
       "       -0.6885003 , -0.30154693, -1.708323  ,  1.1030879 , -2.2597387 ,\n",
       "        1.1909146 ,  2.4399316 ,  0.3990314 ,  0.904154  ,  0.5454401 ,\n",
       "       -1.3235748 , -0.64812386,  0.22390233,  0.9657619 , -0.47360668,\n",
       "       -0.10278235, -1.0679734 , -0.91414386,  0.92069   ,  0.3549338 ,\n",
       "        0.32858834,  0.84870636,  3.596926  , -1.6651102 ,  0.23658653,\n",
       "        1.0515738 ,  0.40531915, -0.773514  , -0.93460965, -0.3946274 ,\n",
       "       -1.5657727 ,  1.183652  ,  2.5277    ,  0.57700926,  1.7051374 ,\n",
       "       -1.8249958 , -2.0328498 ,  0.6617798 ,  0.85747904,  0.31782728,\n",
       "       -1.1660796 ,  0.32923874,  2.2055087 , -0.12782003,  2.0455444 ,\n",
       "       -0.1724252 ,  0.46001154,  1.559042  , -1.6152996 , -0.84242785,\n",
       "        0.7553168 ,  0.39734274,  0.07714175,  0.05610155,  0.32837135,\n",
       "        1.0220716 ,  1.3816743 ,  0.8049544 ,  0.28728685, -0.97610044,\n",
       "        0.8861181 , -0.01250968, -1.4845604 , -1.5236791 , -1.5451258 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = word2vec['사랑']\n",
    "v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f87a8d24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1174/1073688978.py:8: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  if index_to_word[i] in word2vec:\n",
      "/tmp/ipykernel_1174/1073688978.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  embedding_matrix[i] = word2vec[index_to_word[i]]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "word_vector_dim = 200\n",
    "\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bb95ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 41, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               467968    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 2056      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,470,033\n",
      "Trainable params: 2,470,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000\n",
    "word_vector_dim = 200\n",
    "\n",
    "# 모델 구성\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix), \n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "\n",
    "model.add(keras.layers.LSTM(256))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "810d35c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "986/986 [==============================] - 12s 11ms/step - loss: 0.4990 - accuracy: 0.7341 - val_loss: 0.3670 - val_accuracy: 0.8450\n",
      "Epoch 2/20\n",
      "986/986 [==============================] - 10s 10ms/step - loss: 0.3270 - accuracy: 0.8588 - val_loss: 0.3194 - val_accuracy: 0.8615\n",
      "Epoch 3/20\n",
      "986/986 [==============================] - 10s 10ms/step - loss: 0.2803 - accuracy: 0.8816 - val_loss: 0.3150 - val_accuracy: 0.8666\n",
      "Epoch 4/20\n",
      "986/986 [==============================] - 10s 10ms/step - loss: 0.2481 - accuracy: 0.8972 - val_loss: 0.3178 - val_accuracy: 0.8688\n",
      "Epoch 5/20\n",
      "986/986 [==============================] - 10s 10ms/step - loss: 0.2168 - accuracy: 0.9118 - val_loss: 0.3282 - val_accuracy: 0.8655\n",
      "Epoch 6/20\n",
      "986/986 [==============================] - 10s 10ms/step - loss: 0.1861 - accuracy: 0.9258 - val_loss: 0.3391 - val_accuracy: 0.8686\n",
      "Epoch 7/20\n",
      "986/986 [==============================] - 10s 11ms/step - loss: 0.1575 - accuracy: 0.9387 - val_loss: 0.3928 - val_accuracy: 0.8651\n",
      "Epoch 8/20\n",
      "986/986 [==============================] - 10s 10ms/step - loss: 0.1325 - accuracy: 0.9495 - val_loss: 0.3879 - val_accuracy: 0.8601\n",
      "Epoch 9/20\n",
      "986/986 [==============================] - 10s 10ms/step - loss: 0.1097 - accuracy: 0.9596 - val_loss: 0.4629 - val_accuracy: 0.8612\n",
      "Epoch 10/20\n",
      "986/986 [==============================] - 10s 10ms/step - loss: 0.0922 - accuracy: 0.9667 - val_loss: 0.4688 - val_accuracy: 0.8619\n",
      "Epoch 11/20\n",
      "986/986 [==============================] - 10s 11ms/step - loss: 0.0769 - accuracy: 0.9728 - val_loss: 0.5252 - val_accuracy: 0.8569\n",
      "Epoch 12/20\n",
      "986/986 [==============================] - 10s 10ms/step - loss: 0.0677 - accuracy: 0.9760 - val_loss: 0.5587 - val_accuracy: 0.8579\n",
      "Epoch 13/20\n",
      "986/986 [==============================] - 10s 10ms/step - loss: 0.0593 - accuracy: 0.9791 - val_loss: 0.5828 - val_accuracy: 0.8583\n",
      "Epoch 14/20\n",
      "986/986 [==============================] - 10s 10ms/step - loss: 0.0530 - accuracy: 0.9812 - val_loss: 0.6461 - val_accuracy: 0.8577\n",
      "Epoch 15/20\n",
      "986/986 [==============================] - 10s 10ms/step - loss: 0.0472 - accuracy: 0.9827 - val_loss: 0.6570 - val_accuracy: 0.8562\n",
      "Epoch 16/20\n",
      "986/986 [==============================] - 10s 10ms/step - loss: 0.0430 - accuracy: 0.9840 - val_loss: 0.6933 - val_accuracy: 0.8540\n",
      "Epoch 17/20\n",
      "986/986 [==============================] - 10s 10ms/step - loss: 0.0415 - accuracy: 0.9842 - val_loss: 0.6793 - val_accuracy: 0.8581\n",
      "Epoch 18/20\n",
      "986/986 [==============================] - 10s 10ms/step - loss: 0.0365 - accuracy: 0.9860 - val_loss: 0.7267 - val_accuracy: 0.8572\n",
      "Epoch 19/20\n",
      "986/986 [==============================] - 10s 10ms/step - loss: 0.0341 - accuracy: 0.9870 - val_loss: 0.7110 - val_accuracy: 0.8559\n",
      "Epoch 20/20\n",
      "986/986 [==============================] - 10s 10ms/step - loss: 0.0310 - accuracy: 0.9881 - val_loss: 0.7617 - val_accuracy: 0.8575\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20\n",
    "\n",
    "history = model.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=128,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6471c0",
   "metadata": {},
   "source": [
    "- 0.848 -> 0.854로 성능 향상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "880b823c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2205cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2668bd58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
