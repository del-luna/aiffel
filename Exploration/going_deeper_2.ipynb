{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "going_deeper_2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPjcj4bmecqQ"
      },
      "outputs": [],
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    'cats_vs_dogs',\n",
        "    split = ('train[:80%]', 'train[80%:]'),\n",
        "    with_info = True,\n",
        "    as_supervised = True\n",
        ")"
      ],
      "metadata": {
        "id": "eNsjS6r_ehw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_image(image, label):\n",
        "    image = tf.image.resize(image, (SIZE, SIZE))/255.0\n",
        "    return image, label\n",
        "\n",
        "num_examples = ds_info.splits['train'].num_examples\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "SIZE = 224\n",
        "\n",
        "train_batches = ds_train.cache().shuffle(num_examples//4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "validation_batches = ds_test.map(format_image).batch(BATCH_SIZE).prefetch(1)"
      ],
      "metadata": {
        "id": "PgPFHvgye9L5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock2(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, filter_num, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters=filter_num,\n",
        "                                            kernel_size=(3,3),\n",
        "                                            strides=stride,\n",
        "                                            padding='same')\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.conv2 = tf.keras.layers.Conv2D(filters=filter_num,\n",
        "                                            kernel_size=(3,3),\n",
        "                                            strides=1,\n",
        "                                            padding='same')\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "        if stride != 1:\n",
        "            self.shortcut = tf.keras.Sequential()\n",
        "            self.shortcut.add(tf.keras.layers.Conv2D(filters=filter_num,\n",
        "                                                     kernel_size=(1,1),\n",
        "                                                     strides=stride))\n",
        "            self.shortcut.add(tf.keras.layers.BatchNormalization())\n",
        "        else:\n",
        "            self.shortcut = lambda x: x\n",
        "\n",
        "    def call(self, inputs, training=None, **kwargs):\n",
        "        residual = self.shortcut(inputs)\n",
        "\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x, training=training)\n",
        "\n",
        "        output = tf.nn.relu(x)\n",
        "\n",
        "        return output\n",
        "\n",
        "class BottleNeck2(tf.keras.layers.Layer):\n",
        "    def __init__(self, filter_num, stride=1):\n",
        "        super(BottleNeck, self).__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters=filter_num,\n",
        "                                            kernel_size=(1, 1),\n",
        "                                            strides=1,\n",
        "                                            padding='same')\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.conv2 = tf.keras.layers.Conv2D(filters=filter_num,\n",
        "                                            kernel_size=(3, 3),\n",
        "                                            strides=stride,\n",
        "                                            padding='same')\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "        self.conv3 = tf.keras.layers.Conv2D(filters=filter_num * 4,\n",
        "                                            kernel_size=(1, 1),\n",
        "                                            strides=1,\n",
        "                                            padding='same')\n",
        "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "        self.downsample = tf.keras.Sequential()\n",
        "        self.downsample.add(tf.keras.layers.Conv2D(filters=filter_num * 4,\n",
        "                                                   kernel_size=(1, 1),\n",
        "                                                   strides=stride))\n",
        "        self.downsample.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    def call(self, inputs, training=None, **kwargs):\n",
        "        residual = self.downsample(inputs)\n",
        "\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x, training=training)\n",
        "\n",
        "        output = tf.nn.relu(x)\n",
        "\n",
        "        return output\n",
        "\n",
        "def make_basic_block_layer2(filter_num, blocks, stride=1):\n",
        "    res_block = tf.keras.Sequential()\n",
        "    res_block.add(BasicBlock(filter_num, stride=stride))\n",
        "\n",
        "    for _ in range(1, blocks):\n",
        "        res_block.add(BasicBlock(filter_num, stride=1))\n",
        "\n",
        "    return res_block\n",
        "\n",
        "\n",
        "def make_bottleneck_layer2(filter_num, blocks, stride=1):\n",
        "    res_block = tf.keras.Sequential()\n",
        "    res_block.add(BottleNeck(filter_num, stride=stride))\n",
        "\n",
        "    for _ in range(1, blocks):\n",
        "        res_block.add(BottleNeck(filter_num, stride=1))\n",
        "\n",
        "    return res_block"
      ],
      "metadata": {
        "id": "fIoy_QSf8-m9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetTypeIII(tf.keras.Model):\n",
        "    def __init__(self, layer_params):\n",
        "        super(ResNetTypeI, self).__init__()\n",
        "\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters=64,\n",
        "                                            kernel_size=(7, 7),\n",
        "                                            strides=2,\n",
        "                                            padding=\"same\")\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n",
        "                                               strides=2,\n",
        "                                               padding=\"same\")\n",
        "\n",
        "        self.layer1 = make_basic_block_layer2(filter_num=64,\n",
        "                                             blocks=layer_params[0])\n",
        "        self.layer2 = make_basic_block_layer2(filter_num=128,\n",
        "                                             blocks=layer_params[1],\n",
        "                                             stride=2)\n",
        "        self.layer3 = make_basic_block_layer2(filter_num=256,\n",
        "                                             blocks=layer_params[2],\n",
        "                                             stride=2)\n",
        "        self.layer4 = make_basic_block_layer2(filter_num=512,\n",
        "                                             blocks=layer_params[3],\n",
        "                                             stride=2)\n",
        "\n",
        "        self.avgpool = tf.keras.layers.GlobalAveragePooling2D()\n",
        "        self.fc = tf.keras.layers.Dense(units=2, activation=tf.keras.activations.softmax)\n",
        "\n",
        "    def call(self, inputs, training=None, mask=None):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.layer1(x, training=training)\n",
        "        x = self.layer2(x, training=training)\n",
        "        x = self.layer3(x, training=training)\n",
        "        x = self.layer4(x, training=training)\n",
        "        x = self.avgpool(x)\n",
        "        output = self.fc(x)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class ResNetTypeIV(tf.keras.Model):\n",
        "    def __init__(self, layer_params):\n",
        "        super(ResNetTypeII, self).__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters=64,\n",
        "                                            kernel_size=(7, 7),\n",
        "                                            strides=2,\n",
        "                                            padding=\"same\")\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n",
        "                                               strides=2,\n",
        "                                               padding=\"same\")\n",
        "\n",
        "        self.layer1 = make_bottleneck_layer2(filter_num=64,\n",
        "                                            blocks=layer_params[0])\n",
        "        self.layer2 = make_bottleneck_layer2(filter_num=128,\n",
        "                                            blocks=layer_params[1],\n",
        "                                            stride=2)\n",
        "        self.layer3 = make_bottleneck_layer2(filter_num=256,\n",
        "                                            blocks=layer_params[2],\n",
        "                                            stride=2)\n",
        "        self.layer4 = make_bottleneck_layer2(filter_num=512,\n",
        "                                            blocks=layer_params[3],\n",
        "                                            stride=2)\n",
        "\n",
        "        self.avgpool = tf.keras.layers.GlobalAveragePooling2D()\n",
        "        self.fc = tf.keras.layers.Dense(units=2, activation=tf.keras.activations.softmax)\n",
        "\n",
        "    def call(self, inputs, training=None, mask=None):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.layer1(x, training=training)\n",
        "        x = self.layer2(x, training=training)\n",
        "        x = self.layer3(x, training=training)\n",
        "        x = self.layer4(x, training=training)\n",
        "        x = self.avgpool(x)\n",
        "        output = self.fc(x)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "def resnet_18_2():\n",
        "    return ResNetTypeIII(layer_params=[2, 2, 2, 2])\n",
        "\n",
        "\n",
        "def resnet_34_2():\n",
        "    return ResNetTypeIII(layer_params=[3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def resnet_50_2():\n",
        "    return ResNetTypeIV(layer_params=[3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def resnet_101_2():\n",
        "    return ResNetTypeIV(layer_params=[3, 4, 23, 3])\n",
        "\n",
        "\n",
        "def resnet_152_2():\n",
        "    return ResNetTypeIV(layer_params=[3, 8, 36, 3])"
      ],
      "metadata": {
        "id": "Jjj_l6CS90zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, filter_num, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters=filter_num,\n",
        "                                            kernel_size=(3,3),\n",
        "                                            strides=stride,\n",
        "                                            padding='same')\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.conv2 = tf.keras.layers.Conv2D(filters=filter_num,\n",
        "                                            kernel_size=(3,3),\n",
        "                                            strides=1,\n",
        "                                            padding='same')\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "        if stride != 1:\n",
        "            self.shortcut = tf.keras.Sequential()\n",
        "            self.shortcut.add(tf.keras.layers.Conv2D(filters=filter_num,\n",
        "                                                     kernel_size=(1,1),\n",
        "                                                     strides=stride))\n",
        "            self.shortcut.add(tf.keras.layers.BatchNormalization())\n",
        "        else:\n",
        "            self.shortcut = lambda x: x\n",
        "\n",
        "    def call(self, inputs, training=None, **kwargs):\n",
        "        residual = self.shortcut(inputs)\n",
        "\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x, training=training)\n",
        "\n",
        "        output = tf.nn.relu(tf.keras.layers.add([residual, x]))\n",
        "\n",
        "        return output\n",
        "\n",
        "class BottleNeck(tf.keras.layers.Layer):\n",
        "    def __init__(self, filter_num, stride=1):\n",
        "        super(BottleNeck, self).__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters=filter_num,\n",
        "                                            kernel_size=(1, 1),\n",
        "                                            strides=1,\n",
        "                                            padding='same')\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.conv2 = tf.keras.layers.Conv2D(filters=filter_num,\n",
        "                                            kernel_size=(3, 3),\n",
        "                                            strides=stride,\n",
        "                                            padding='same')\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "        self.conv3 = tf.keras.layers.Conv2D(filters=filter_num * 4,\n",
        "                                            kernel_size=(1, 1),\n",
        "                                            strides=1,\n",
        "                                            padding='same')\n",
        "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "        self.downsample = tf.keras.Sequential()\n",
        "        self.downsample.add(tf.keras.layers.Conv2D(filters=filter_num * 4,\n",
        "                                                   kernel_size=(1, 1),\n",
        "                                                   strides=stride))\n",
        "        self.downsample.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    def call(self, inputs, training=None, **kwargs):\n",
        "        residual = self.downsample(inputs)\n",
        "\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x, training=training)\n",
        "\n",
        "        output = tf.nn.relu(tf.keras.layers.add([residual, x]))\n",
        "\n",
        "        return output\n",
        "\n",
        "def make_basic_block_layer(filter_num, blocks, stride=1):\n",
        "    res_block = tf.keras.Sequential()\n",
        "    res_block.add(BasicBlock(filter_num, stride=stride))\n",
        "\n",
        "    for _ in range(1, blocks):\n",
        "        res_block.add(BasicBlock(filter_num, stride=1))\n",
        "\n",
        "    return res_block\n",
        "\n",
        "\n",
        "def make_bottleneck_layer(filter_num, blocks, stride=1):\n",
        "    res_block = tf.keras.Sequential()\n",
        "    res_block.add(BottleNeck(filter_num, stride=stride))\n",
        "\n",
        "    for _ in range(1, blocks):\n",
        "        res_block.add(BottleNeck(filter_num, stride=1))\n",
        "\n",
        "    return res_block"
      ],
      "metadata": {
        "id": "YOiNB_oUgnGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetTypeI(tf.keras.Model):\n",
        "    def __init__(self, layer_params):\n",
        "        super(ResNetTypeI, self).__init__()\n",
        "\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters=64,\n",
        "                                            kernel_size=(7, 7),\n",
        "                                            strides=2,\n",
        "                                            padding=\"same\")\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n",
        "                                               strides=2,\n",
        "                                               padding=\"same\")\n",
        "\n",
        "        self.layer1 = make_basic_block_layer(filter_num=64,\n",
        "                                             blocks=layer_params[0])\n",
        "        self.layer2 = make_basic_block_layer(filter_num=128,\n",
        "                                             blocks=layer_params[1],\n",
        "                                             stride=2)\n",
        "        self.layer3 = make_basic_block_layer(filter_num=256,\n",
        "                                             blocks=layer_params[2],\n",
        "                                             stride=2)\n",
        "        self.layer4 = make_basic_block_layer(filter_num=512,\n",
        "                                             blocks=layer_params[3],\n",
        "                                             stride=2)\n",
        "\n",
        "        self.avgpool = tf.keras.layers.GlobalAveragePooling2D()\n",
        "        self.fc = tf.keras.layers.Dense(units=2, activation=tf.keras.activations.softmax)\n",
        "\n",
        "    def call(self, inputs, training=None, mask=None):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.layer1(x, training=training)\n",
        "        x = self.layer2(x, training=training)\n",
        "        x = self.layer3(x, training=training)\n",
        "        x = self.layer4(x, training=training)\n",
        "        x = self.avgpool(x)\n",
        "        output = self.fc(x)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class ResNetTypeII(tf.keras.Model):\n",
        "    def __init__(self, layer_params):\n",
        "        super(ResNetTypeII, self).__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters=64,\n",
        "                                            kernel_size=(7, 7),\n",
        "                                            strides=2,\n",
        "                                            padding=\"same\")\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n",
        "                                               strides=2,\n",
        "                                               padding=\"same\")\n",
        "\n",
        "        self.layer1 = make_bottleneck_layer(filter_num=64,\n",
        "                                            blocks=layer_params[0])\n",
        "        self.layer2 = make_bottleneck_layer(filter_num=128,\n",
        "                                            blocks=layer_params[1],\n",
        "                                            stride=2)\n",
        "        self.layer3 = make_bottleneck_layer(filter_num=256,\n",
        "                                            blocks=layer_params[2],\n",
        "                                            stride=2)\n",
        "        self.layer4 = make_bottleneck_layer(filter_num=512,\n",
        "                                            blocks=layer_params[3],\n",
        "                                            stride=2)\n",
        "\n",
        "        self.avgpool = tf.keras.layers.GlobalAveragePooling2D()\n",
        "        self.fc = tf.keras.layers.Dense(units=2, activation=tf.keras.activations.softmax)\n",
        "\n",
        "    def call(self, inputs, training=None, mask=None):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.layer1(x, training=training)\n",
        "        x = self.layer2(x, training=training)\n",
        "        x = self.layer3(x, training=training)\n",
        "        x = self.layer4(x, training=training)\n",
        "        x = self.avgpool(x)\n",
        "        output = self.fc(x)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "def resnet_18():\n",
        "    return ResNetTypeI(layer_params=[2, 2, 2, 2])\n",
        "\n",
        "\n",
        "def resnet_34():\n",
        "    return ResNetTypeI(layer_params=[3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def resnet_50():\n",
        "    return ResNetTypeII(layer_params=[3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def resnet_101():\n",
        "    return ResNetTypeII(layer_params=[3, 4, 23, 3])\n",
        "\n",
        "\n",
        "def resnet_152():\n",
        "    return ResNetTypeII(layer_params=[3, 8, 36, 3])"
      ],
      "metadata": {
        "id": "NmMWnU2Gl6RJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(type='resnet34'):\n",
        "    if type == 'resenet50':\n",
        "        model = resnet_50()\n",
        "    else:\n",
        "        model = resnet_34()\n",
        "    model.build(input_shape=(None, 224, 224, 3))\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "model = get_model()"
      ],
      "metadata": {
        "id": "EaSXiJPamHm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adadelta()\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "valid_loss = tf.keras.metrics.Mean(name='valid_loss')\n",
        "valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='valid_accuracy')"
      ],
      "metadata": {
        "id": "egNcqYDZnUXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(images, training=True)\n",
        "        loss = loss_object(y_true=labels, y_pred=predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(grads_and_vars=zip(gradients, model.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(labels, predictions)\n",
        "\n",
        "@tf.function\n",
        "def valid_step(images, labels):\n",
        "    predictions = model(images, training=False)\n",
        "    v_loss = loss_object(labels, predictions)\n",
        "\n",
        "    valid_loss(v_loss)\n",
        "    valid_accuracy(labels, predictions)\n",
        "\n",
        "# start training\n",
        "for epoch in range(30):\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    valid_loss.reset_states()\n",
        "    valid_accuracy.reset_states()\n",
        "    step = 0\n",
        "    for images, labels in train_batches:\n",
        "        step += 1\n",
        "        train_step(images, labels)\n",
        "        print(\"Epoch: {}/{}, step: {}/{}, loss: {:.5f}, accuracy: {:.5f}\".format(epoch + 1,\n",
        "                                                                                    30,\n",
        "                                                                                    step,\n",
        "                                                                                    math.ceil(num_examples / 64),\n",
        "                                                                                    train_loss.result(),\n",
        "                                                                                    train_accuracy.result()))\n",
        "\n",
        "    for valid_images, valid_labels in validation_batches:\n",
        "        valid_step(valid_images, valid_labels)\n",
        "\n",
        "    print(\"Epoch: {}/{}, train loss: {:.5f}, train accuracy: {:.5f}, \"\n",
        "            \"valid loss: {:.5f}, valid accuracy: {:.5f}\".format(epoch + 1,\n",
        "                                                                30,\n",
        "                                                                train_loss.result(),\n",
        "                                                                train_accuracy.result(),\n",
        "                                                                valid_loss.result(),\n",
        "                                                                valid_accuracy.result()))"
      ],
      "metadata": {
        "id": "GbqKpq6hobZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "model = get_model('resnet50')\n",
        "\n",
        "import math\n",
        "\n",
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(images, training=True)\n",
        "        loss = loss_object(y_true=labels, y_pred=predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(grads_and_vars=zip(gradients, model.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(labels, predictions)\n",
        "\n",
        "@tf.function\n",
        "def valid_step(images, labels):\n",
        "    predictions = model(images, training=False)\n",
        "    v_loss = loss_object(labels, predictions)\n",
        "\n",
        "    valid_loss(v_loss)\n",
        "    valid_accuracy(labels, predictions)\n",
        "\n",
        "# start training\n",
        "for epoch in range(30):\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    valid_loss.reset_states()\n",
        "    valid_accuracy.reset_states()\n",
        "    step = 0\n",
        "    for images, labels in train_batches:\n",
        "        step += 1\n",
        "        train_step(images, labels)\n",
        "        print(\"Epoch: {}/{}, step: {}/{}, loss: {:.5f}, accuracy: {:.5f}\".format(epoch + 1,\n",
        "                                                                                    30,\n",
        "                                                                                    step,\n",
        "                                                                                    math.ceil(num_examples / 64),\n",
        "                                                                                    train_loss.result(),\n",
        "                                                                                    train_accuracy.result()))\n",
        "\n",
        "    for valid_images, valid_labels in validation_batches:\n",
        "        valid_step(valid_images, valid_labels)\n",
        "\n",
        "    print(\"Epoch: {}/{}, train loss: {:.5f}, train accuracy: {:.5f}, \"\n",
        "            \"valid loss: {:.5f}, valid accuracy: {:.5f}\".format(epoch + 1,\n",
        "                                                                30,\n",
        "                                                                train_loss.result(),\n",
        "                                                                train_accuracy.result(),\n",
        "                                                                valid_loss.result(),\n",
        "                                                                valid_accuracy.result()))"
      ],
      "metadata": {
        "id": "GiS5PYQjo3zK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(type='resnet34_2'):\n",
        "    if type == 'resenet50_2':\n",
        "        model = resnet_50_2()\n",
        "    else:\n",
        "        model = resnet_34()\n",
        "    model.build(input_shape=(None, 224, 224, 3))\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "model = get_model()\n",
        "\n",
        "import math\n",
        "\n",
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(images, training=True)\n",
        "        loss = loss_object(y_true=labels, y_pred=predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(grads_and_vars=zip(gradients, model.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(labels, predictions)\n",
        "\n",
        "@tf.function\n",
        "def valid_step(images, labels):\n",
        "    predictions = model(images, training=False)\n",
        "    v_loss = loss_object(labels, predictions)\n",
        "\n",
        "    valid_loss(v_loss)\n",
        "    valid_accuracy(labels, predictions)\n",
        "\n",
        "# start training\n",
        "for epoch in range(30):\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    valid_loss.reset_states()\n",
        "    valid_accuracy.reset_states()\n",
        "    step = 0\n",
        "    for images, labels in train_batches:\n",
        "        step += 1\n",
        "        train_step(images, labels)\n",
        "        print(\"Epoch: {}/{}, step: {}/{}, loss: {:.5f}, accuracy: {:.5f}\".format(epoch + 1,\n",
        "                                                                                    30,\n",
        "                                                                                    step,\n",
        "                                                                                    math.ceil(num_examples / 64),\n",
        "                                                                                    train_loss.result(),\n",
        "                                                                                    train_accuracy.result()))\n",
        "\n",
        "    for valid_images, valid_labels in validation_batches:\n",
        "        valid_step(valid_images, valid_labels)\n",
        "\n",
        "    print(\"Epoch: {}/{}, train loss: {:.5f}, train accuracy: {:.5f}, \"\n",
        "            \"valid loss: {:.5f}, valid accuracy: {:.5f}\".format(epoch + 1,\n",
        "                                                                30,\n",
        "                                                                train_loss.result(),\n",
        "                                                                train_accuracy.result(),\n",
        "                                                                valid_loss.result(),\n",
        "                                                                valid_accuracy.result()))"
      ],
      "metadata": {
        "id": "xj7JlI2K3cL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(type='resnet34_2'):\n",
        "    if type == 'resenet50_2':\n",
        "        model = resnet_50_2()\n",
        "    else:\n",
        "        model = resnet_34()\n",
        "    model.build(input_shape=(None, 224, 224, 3))\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "model = get_model('resnet_50_2')\n",
        "\n",
        "import math\n",
        "\n",
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(images, training=True)\n",
        "        loss = loss_object(y_true=labels, y_pred=predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(grads_and_vars=zip(gradients, model.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(labels, predictions)\n",
        "\n",
        "@tf.function\n",
        "def valid_step(images, labels):\n",
        "    predictions = model(images, training=False)\n",
        "    v_loss = loss_object(labels, predictions)\n",
        "\n",
        "    valid_loss(v_loss)\n",
        "    valid_accuracy(labels, predictions)\n",
        "\n",
        "# start training\n",
        "for epoch in range(30):\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    valid_loss.reset_states()\n",
        "    valid_accuracy.reset_states()\n",
        "    step = 0\n",
        "    for images, labels in train_batches:\n",
        "        step += 1\n",
        "        train_step(images, labels)\n",
        "        print(\"Epoch: {}/{}, step: {}/{}, loss: {:.5f}, accuracy: {:.5f}\".format(epoch + 1,\n",
        "                                                                                    30,\n",
        "                                                                                    step,\n",
        "                                                                                    math.ceil(num_examples / 64),\n",
        "                                                                                    train_loss.result(),\n",
        "                                                                                    train_accuracy.result()))\n",
        "\n",
        "    for valid_images, valid_labels in validation_batches:\n",
        "        valid_step(valid_images, valid_labels)\n",
        "\n",
        "    print(\"Epoch: {}/{}, train loss: {:.5f}, train accuracy: {:.5f}, \"\n",
        "            \"valid loss: {:.5f}, valid accuracy: {:.5f}\".format(epoch + 1,\n",
        "                                                                30,\n",
        "                                                                train_loss.result(),\n",
        "                                                                train_accuracy.result(),\n",
        "                                                                valid_loss.result(),\n",
        "                                                                valid_accuracy.result()))"
      ],
      "metadata": {
        "id": "K4kUXkdV-TQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Plain Network\n",
        "    - Plain_34\n",
        "        - train: 0.94, valid: 0.68\n",
        "    - Plain_50\n",
        "        - train: 0.95, valid: 0.66\n",
        "*   ResNet\n",
        "    - ResNet_34\n",
        "        - train: 0.93, valid: 0.69\n",
        "    - ResNet_50\n",
        "        - train: 0.95, valid: 0.68\n"
      ],
      "metadata": {
        "id": "L-hTrEpO_jBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1vYz-K2mfoqp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}